{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "# Import argsort\n",
    "from numpy import argsort\n",
    "from Functions.connection.connection import *\n",
    "from Functions.AlertP1.data_cleaning import *\n",
    "from Functions.AlertP1.features import *\n",
    "from Functions.analysis.step_analysis import *\n",
    "from Functions.AlertP1.dummy_features import *\n",
    "from Functions.Models.xgboost import *\n",
    "from Functions.Models.evaluation import *\n",
    "from Functions.NLP.alertp1_nlp import *\n",
    "from Functions.NLP.data_with_nlp import *\n",
    "from Functions.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "alertP1=connection(\"credentials.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "data = pre_process(alertP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "def ner_features(df, column):\n",
    "    import spacy\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    nlp = spacy.load('pt_core_news_md')\n",
    "    ner = []\n",
    "    for doc in nlp.pipe(df[column]):\n",
    "        doc_ner = []\n",
    "        for ent in doc.ents:\n",
    "            doc_ner.append((ent.text, ent.label_))\n",
    "        ner.append(doc_ner)\n",
    "    df['ner'] = ner\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "new_data = ner_features(data, \"clean_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def one_hot_encode_ner(df):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    ner_one_hot = mlb.fit_transform(df['ner'].apply(lambda x: [label for _, label in x]))\n",
    "    ner_df = pd.DataFrame(ner_one_hot, columns=mlb.classes_)\n",
    "    return pd.concat([df, ner_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "new_data = new_data.reset_index(drop=True)\n",
    "new_data = one_hot_encode_ner(new_data)\n",
    "new_data = new_data.drop('ner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "eliminate_cols=['ID_DOENTE','PROCESSO','COD_REFERENCIA','result','COD_PZ','COD_UNID_SAUDE_PROV','UNID_PROV','TIPO_UNID','COD_CTH_PRIOR','CTH_PRIOR','COD_MOTIVO_RECUSA','DES_MOTIVO_RECUSA','COD_ESPECIALIDADE','DES_ESPECIALIDADE','agrupadora','OUTRA_ENTIDADE','DATA_RECEPCAO','DATA_ENVIO','DATA_RETORNO','NUM_TAXA','ESTADO','DATA_MARCACAO','DATA_REALIZACAO','OBSERVACOES','Mês_entrada','Ano_entrada','trata data recusa','resume saída','mês_saida','ano_saida','Texto','clean_text']\n",
    "X = new_data.drop(eliminate_cols,axis=1)# Features\n",
    "y = new_data.result # Target variable\n",
    "features=X.columns\n",
    "\n",
    "y_pred_train, y_pred_test, model_score, X_train, X_test, y_train, y_test = xgb_classifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot the feature importance scores\n",
    "plot_importance(model_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_thresholds(y_pred_train,y_train,y_pred_test,y_test,metrics=\"test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRYING TOPIC LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_words(lda, vectorizer, n_top_words=10):\n",
    "    # Extract top words for each topic\n",
    "    top_words = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "    # Print top words for each topic\n",
    "    for i, words in enumerate(top_words):\n",
    "        print(f'Topic {i}: ' + ', '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def lda_topics(df, column, n_components=5):\n",
    "    # Convert text data into a bag of words representation\n",
    "    vectorizer = CountVectorizer(analyzer='word',min_df=10)\n",
    "    data_vectorized = vectorizer.fit_transform(df[column])\n",
    "\n",
    "    # Fit LDA model to the data\n",
    "    lda = LatentDirichletAllocation(n_components=n_components)\n",
    "    lda.fit(data_vectorized)\n",
    "\n",
    "    # Transform data to get topic distribution for each row\n",
    "    topic_dist = lda.transform(data_vectorized)\n",
    "\n",
    "    # Create new dataframe with topic columns\n",
    "    topic_columns = [f'topic_{i}' for i in range(n_components)]\n",
    "    topic_df = pd.DataFrame(topic_dist, columns=topic_columns)\n",
    "\n",
    "    # Concatenate topic dataframe with original dataframe\n",
    "    df = pd.concat([df.reset_index(drop=True), topic_df], axis=1)\n",
    "                   \n",
    "    get_top_words(lda, vectorizer)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "lda_data = lda_topics(data,\"clean_text\")\n",
    "lda_data = lda_data.drop('ner', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "lda_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "eliminate_cols=['ID_DOENTE','PROCESSO','COD_REFERENCIA','result','COD_PZ','COD_UNID_SAUDE_PROV','UNID_PROV','TIPO_UNID','COD_CTH_PRIOR','CTH_PRIOR','COD_MOTIVO_RECUSA','DES_MOTIVO_RECUSA','COD_ESPECIALIDADE','DES_ESPECIALIDADE','agrupadora','OUTRA_ENTIDADE','DATA_RECEPCAO','DATA_ENVIO','DATA_RETORNO','NUM_TAXA','ESTADO','DATA_MARCACAO','DATA_REALIZACAO','OBSERVACOES','Mês_entrada','Ano_entrada','trata data recusa','resume saída','mês_saida','ano_saida','Texto','clean_text']\n",
    "X = lda_data.drop(eliminate_cols,axis=1)# Features\n",
    "y = lda_data.result # Target variable\n",
    "features=X.columns\n",
    "\n",
    "y_pred_train, y_pred_test, model_score, X_train, X_test, y_train, y_test = xgb_classifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot the feature importance scores\n",
    "plot_importance(model_score)\n",
    "plt.show()\n",
    "evaluate_thresholds(y_pred_train,y_train,y_pred_test,y_test,metrics=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "lda_data = lda_topics(data,\"clean_text\",20)\n",
    "lda_data = lda_data.drop('ner', axis=1)\n",
    "eliminate_cols=['ID_DOENTE','PROCESSO','COD_REFERENCIA','result','COD_PZ','COD_UNID_SAUDE_PROV','UNID_PROV','TIPO_UNID','COD_CTH_PRIOR','CTH_PRIOR','COD_MOTIVO_RECUSA','DES_MOTIVO_RECUSA','COD_ESPECIALIDADE','DES_ESPECIALIDADE','agrupadora','OUTRA_ENTIDADE','DATA_RECEPCAO','DATA_ENVIO','DATA_RETORNO','NUM_TAXA','ESTADO','DATA_MARCACAO','DATA_REALIZACAO','OBSERVACOES','Mês_entrada','Ano_entrada','trata data recusa','resume saída','mês_saida','ano_saida','Texto','clean_text']\n",
    "X = lda_data.drop(eliminate_cols,axis=1)# Features\n",
    "y = lda_data.result # Target variable\n",
    "features=X.columns\n",
    "\n",
    "y_pred_train, y_pred_test, model_score, X_train, X_test, y_train, y_test = xgb_classifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot the feature importance scores\n",
    "plot_importance(model_score)\n",
    "plt.show()\n",
    "evaluate_thresholds(y_pred_train,y_train,y_pred_test,y_test,metrics=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "lda_data = lda_topics(data,\"clean_text\",100)\n",
    "lda_data = lda_data.drop('ner', axis=1)\n",
    "eliminate_cols=['ID_DOENTE','PROCESSO','COD_REFERENCIA','result','COD_PZ','COD_UNID_SAUDE_PROV','UNID_PROV','TIPO_UNID','COD_CTH_PRIOR','CTH_PRIOR','COD_MOTIVO_RECUSA','DES_MOTIVO_RECUSA','COD_ESPECIALIDADE','DES_ESPECIALIDADE','agrupadora','OUTRA_ENTIDADE','DATA_RECEPCAO','DATA_ENVIO','DATA_RETORNO','NUM_TAXA','ESTADO','DATA_MARCACAO','DATA_REALIZACAO','OBSERVACOES','Mês_entrada','Ano_entrada','trata data recusa','resume saída','mês_saida','ano_saida','Texto','clean_text']\n",
    "X = lda_data.drop(eliminate_cols,axis=1)# Features\n",
    "y = lda_data.result # Target variable\n",
    "features=X.columns\n",
    "\n",
    "y_pred_train, y_pred_test, model_score, X_train, X_test, y_train, y_test = xgb_classifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot the feature importance scores\n",
    "plot_importance(model_score)\n",
    "plt.show()\n",
    "evaluate_thresholds(y_pred_train,y_train,y_pred_test,y_test,metrics=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

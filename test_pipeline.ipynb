{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "# Import argsort\n",
    "from numpy import argsort\n",
    "from Functions.connection.connection import *\n",
    "from Functions.AlertP1.data_cleaning import *\n",
    "from Functions.AlertP1.features import *\n",
    "from Functions.analysis.step_analysis import *\n",
    "from Functions.AlertP1.dummy_features import *\n",
    "from Functions.Models.xgboost import *\n",
    "from Functions.Models.evaluation import *\n",
    "from Functions.NLP.alertp1_nlp import *\n",
    "from Functions.NLP.data_with_nlp import *\n",
    "from Functions.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('ConsultaUrgencia_doentespedidosconsultaNeurologia2012',), ('consultaneurologia2012',), ('consultaneurologia201216anon_true',), ('hgo_data_032023',)]\n",
      "715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/connection/connection.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  alertP1 = pd.read_sql(\"\"\"SELECT * FROM consultaneurologia201216anon_true\"\"\",mydb)\n"
     ]
    }
   ],
   "source": [
    "alertP1=connection(\"credentials.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from numpy import argsort\n",
    "from Functions.AlertP1.data_cleaning import *\n",
    "from Functions.AlertP1.features import *\n",
    "from Functions.analysis.step_analysis import *\n",
    "from Functions.AlertP1.dummy_features import *\n",
    "from Functions.Models.xgboost import *\n",
    "from Functions.Models.evaluation import *\n",
    "from Functions.NLP.alertp1_nlp import *\n",
    "from Functions.NLP.data_with_nlp import *\n",
    "\n",
    "def pre_process(df):\n",
    "    #Additional Functions\n",
    "\n",
    "    def sort_values(df):\n",
    "        return df.sort_values('DATA_RECEPCAO')\n",
    "\n",
    "    def text_only(df):\n",
    "        df=df[df['text_length']>0]\n",
    "        return df\n",
    "\n",
    "    def medication_count(df):\n",
    "        df['medication_count']=df['medication_level_1']+df['medication_level_2']+df['medication_level_3']\n",
    "        return df\n",
    "\n",
    "    def medication_concentration(df):\n",
    "        df['medication_concentration']=df['medication_count']/df['text_length']\n",
    "        return df\n",
    "\n",
    "    def column_to_string(df):\n",
    "        for col in df.columns:\n",
    "            if not isinstance(col, str):\n",
    "                df = df.rename(columns={col: str(col)})\n",
    "        return df\n",
    "\n",
    "\n",
    "    #Pipeline\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        #Data Cleaning\n",
    "        ('Date Format', FunctionTransformer(date_format_alertP1)),\n",
    "        ('Replace Blanks', FunctionTransformer(replace_blank)),\n",
    "        ('Duplicated Entities', FunctionTransformer(entity_duplicated)),\n",
    "        ('Lower Case Text ', FunctionTransformer(lowering_text)),\n",
    "        ('Target Variable', FunctionTransformer(result)),\n",
    "        ('Sort Values', FunctionTransformer(sort_values)),\n",
    "        #Structured Features\n",
    "        ('Accepted Before', FunctionTransformer(bef_accepted)),\n",
    "        ('Area Classification', FunctionTransformer(class_area)),\n",
    "        ('Text Length', FunctionTransformer(text_length)),\n",
    "        ('Referral Steps', FunctionTransformer(referral_steps)),\n",
    "        ('Speciality', FunctionTransformer(speciality)),\n",
    "        ('Unit', FunctionTransformer(unit)),\n",
    "        #Dummies\n",
    "        ('Dummies', FunctionTransformer(structured_data_dummies)),\n",
    "        #Keep only text rows\n",
    "        ('Text Only', FunctionTransformer(text_only)),\n",
    "        ('Convert Column Names to String', FunctionTransformer(column_to_string))\n",
    "    ])\n",
    "\n",
    "    transformed_data = pipeline.fit_transform(df)\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['PROVENIENCIA'][alertP1['PROVENIENCIA']=='']='unknown'\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['CTH_PRIOR'][alertP1['CTH_PRIOR']=='']='unknown'\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['COD_UNID_SAUDE_PROV'][alertP1['COD_UNID_SAUDE_PROV']==3151401]=3151400\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['COD_UNID_SAUDE_PROV'][alertP1['COD_UNID_SAUDE_PROV']==3150503]=3150572\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['COD_UNID_SAUDE_PROV'][alertP1['COD_UNID_SAUDE_PROV']==3151603]=3151671\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['COD_UNID_SAUDE_PROV'][alertP1['COD_UNID_SAUDE_PROV']==3152101]=3152100\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/data_cleaning.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['PROVENIENCIA'][alertP1['COD_UNID_SAUDE_PROV']==3150371]='CTH'\n",
      "/Users/miguelcosta/Desktop/PBL/PBL-HGO-1/Functions/AlertP1/features.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alertP1['step'][alertP1['step']>=3]='3+'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pre_process(alertP1)\n",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m, in \u001b[0;36mpre_process\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m#Pipeline\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m     38\u001b[0m     \u001b[39m#Data Cleaning\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mDate Format\u001b[39m\u001b[39m'\u001b[39m, FunctionTransformer(date_format_alertP1)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mConvert Column Names to String\u001b[39m\u001b[39m'\u001b[39m, FunctionTransformer(column_to_string))\n\u001b[1;32m     57\u001b[0m ])\n\u001b[0;32m---> 59\u001b[0m transformed_data \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit_transform(df)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m transformed_data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 437\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    439\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:218\u001b[0m, in \u001b[0;36mFunctionTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit transformer by checking X.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39mIf ``validate`` is ``True``, ``X`` will be checked.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39m    FunctionTransformer class instance.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 218\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input(X, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inverse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_inverse_transform(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:169\u001b[0m, in \u001b[0;36mFunctionTransformer._check_input\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39melif\u001b[39;00m reset:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# Set feature_names_in_ and n_features_in_ even if validate=False\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# We run this only when reset==True to store the attributes but not\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# validate them, because validate=False\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39mreset)\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \n\u001b[1;32m    397\u001b[0m \u001b[39m.. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m reset:\n\u001b[0;32m--> 415\u001b[0m     feature_names_in \u001b[39m=\u001b[39m _get_feature_names(X)\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m feature_names_in \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names_in_ \u001b[39m=\u001b[39m feature_names_in\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/validation.py:1903\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[39m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m types:\n\u001b[0;32m-> 1903\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1904\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names are only supported if all input features have string names, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1905\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut your input has \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m as feature name / column name types. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1906\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1907\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1908\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata, or convert them all to a non-string data type.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1910\u001b[0m     )\n\u001b[1;32m   1912\u001b[0m \u001b[39m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m types[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "data = pre_process(alertP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
